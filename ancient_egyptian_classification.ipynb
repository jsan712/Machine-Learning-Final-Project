{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Ancient Egyptian Landmarks\n",
    "\n",
    "Created by Josh Sanchez. Last updated February 1, 2024.\n",
    "\n",
    "This dataset consists of roughly 3,500 images of Ancient Egyptian landmarks.\n",
    "The dataset was created by user Marvy Ayman Halim on Kaggle and can be found at: https://www.kaggle.com/datasets/marvyaymanhalim/ancient-egyptian-landmarks-dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rsant\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "\n",
    "# data preprocessing\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# data visualization\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# data scaling\n",
    "from preamble import *\n",
    "import mglearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data analysis\n",
    "from mtcnn import MTCNN\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageOps\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Import the data and clean up the folder and file names. Then make the image dataset into a .csv file. \n",
    "\n",
    "**Note:** I manually removed the Node.js folder from the dataset because it does not pertain to the project. The original data can be found under the folder called *Data*. The *raw_data* folder contains the original dataset minus the Node.js folder. The *processed_data folder* contains the properly formatted folder and file names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that you do not have a processed_data folder on your machine, just the raw_data folder, before you run the following two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "labels = []\n",
    "\n",
    "# create the processed_data folder\n",
    "try:\n",
    "    os.mkdir(os.path.join(os.getcwd(), \"processed_data\"))\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "\n",
    "processed_data_dir = os.path.join(os.getcwd(), \"processed_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for folder in os.scandir(\"raw_data\"):\n",
    "    # if the selected item is not a directory\n",
    "    if not folder.is_dir():\n",
    "        continue\n",
    "\n",
    "    # lowercase the folder name and replace space with underscore\n",
    "    changed_folder_name = folder.name.lower()\n",
    "    changed_folder_name = changed_folder_name.replace(\" \", \"_\")\n",
    "\n",
    "    # add folder to processed_data\n",
    "    try:\n",
    "        os.mkdir(os.path.join(processed_data_dir, changed_folder_name))\n",
    "    except OSError as error:\n",
    "        print(error)\n",
    "    processed_folder = os.path.join(processed_data_dir, changed_folder_name)\n",
    "\n",
    "    # pull filename and store in filenames for dataframe\n",
    "    for file in os.scandir(folder.path):\n",
    "        # if the folder is empty\n",
    "        if len(folder.path) == 0:\n",
    "            continue\n",
    "        \n",
    "        # lowercase the file name and replace space with underscore\n",
    "        changed_file_name = file.name.lower()\n",
    "        changed_file_name = changed_file_name.replace(\" \", \"_\")\n",
    "\n",
    "        # copy the file to its correct folder in processed_data\n",
    "        shutil.copy(file, processed_folder)\n",
    "\n",
    "        # rename the file to the edited file name\n",
    "        raw_file = os.path.join(processed_folder, file.name)                 # the original, unedited file name\n",
    "        processed_file = os.path.join(processed_folder, changed_file_name)   # the edited file name\n",
    "        try:\n",
    "            os.rename(raw_file, processed_file)\n",
    "        except OSError as error:\n",
    "            print(error)\n",
    "\n",
    "        # store properly formatted folder name as a label\n",
    "        labels.append(changed_folder_name)\n",
    "\n",
    "        # store filename as a filename\n",
    "        filenames.append(changed_file_name)\n",
    "\n",
    "        # create a dataframe by making a tuple of the filename and label\n",
    "        df = pd.DataFrame(list(zip(filenames, labels)), columns=[\"image\", \"label\"])\n",
    "\n",
    "#change the file to a csv\n",
    "df.to_csv(\"ancient_egyptian_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe the sample and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15634726773_a8ac65d6ef_m_-_copy.jpg</td>\n",
       "      <td>akhenaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19281291360_5a49331215_m.jpg</td>\n",
       "      <td>akhenaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2906415757_50c2bc0414_m.jpg</td>\n",
       "      <td>akhenaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41957529164_421e9f622f_m.jpg</td>\n",
       "      <td>akhenaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4902788942_1c4ee56ede_m.jpg</td>\n",
       "      <td>akhenaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7731634374_fe4e21a493_m.jpg</td>\n",
       "      <td>akhenaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9711457465_051cf60521_n.jpg</td>\n",
       "      <td>akhenaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a.1.jpg</td>\n",
       "      <td>akhenaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a.10.jpg</td>\n",
       "      <td>akhenaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a.11.jpg</td>\n",
       "      <td>akhenaten</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image      label\n",
       "0  15634726773_a8ac65d6ef_m_-_copy.jpg  akhenaten\n",
       "1         19281291360_5a49331215_m.jpg  akhenaten\n",
       "2          2906415757_50c2bc0414_m.jpg  akhenaten\n",
       "3         41957529164_421e9f622f_m.jpg  akhenaten\n",
       "4          4902788942_1c4ee56ede_m.jpg  akhenaten\n",
       "5          7731634374_fe4e21a493_m.jpg  akhenaten\n",
       "6          9711457465_051cf60521_n.jpg  akhenaten\n",
       "7                              a.1.jpg  akhenaten\n",
       "8                             a.10.jpg  akhenaten\n",
       "9                             a.11.jpg  akhenaten"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding patterns/trends in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand the data, it must first be described. The code below shows that there are 1337 \"unique\" images (meaning image filenames) and 22 unique labels. At this point, the model might attempt to cluster the images into 22 distinct groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code shows the number of images for each label. This is the number of points expected for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformations\n",
    "Scale and then grayscale images. Overwrite the image file in processed_data with the transformed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    size = (180, 180)\n",
    "\n",
    "    # if the image is already 180 x 180\n",
    "    if image.size == size:\n",
    "        # print(\"Image is 180: \", image.size)\n",
    "        return image\n",
    "\n",
    "    # if the image is already a square\n",
    "    if image.width == image.height:\n",
    "        square_img = image.resize(size)\n",
    "        # print(\"image is already a square- resize without padding: \", square_img.size)\n",
    "\n",
    "        # save image\n",
    "        square_img = square_img.save(image_path)\n",
    "        return square_img\n",
    "\n",
    "    # if the image's height is smaller than its width\n",
    "    elif image.width > image.height:\n",
    "        # pad the image with black bars to get the image to a square size of its width\n",
    "        square_img = Image.new(image.mode, (image.width, image.width))\n",
    "        square_img.paste(image, (0, (image.width - image.height) // 2))\n",
    "\n",
    "        # resize the image\n",
    "        resized_img = square_img.resize(size)\n",
    "        # print(\"image height is smaller than width- resize with padding for height: \", resized_img.size)\n",
    "\n",
    "        # save image\n",
    "        if resized_img.mode in (\"RGBA\") and (\".jpg\" or \".jpeg\" in image_path):\n",
    "            resized_img = resized_img.convert(\"RGB\")\n",
    "\n",
    "        resized_img = resized_img.save(image_path)\n",
    "        return resized_img\n",
    "\n",
    "    # if the image's width is smaller than its height\n",
    "    else:\n",
    "        square_img = Image.new(image.mode, (image.height, image.height))\n",
    "        square_img.paste(image, ((image.height - image.width) // 2, 0))\n",
    "\n",
    "        # resize the image\n",
    "        resized_img = square_img.resize(size)\n",
    "        # print(\"image width smaller than height- resize with padding for width: \", resized_img.size)\n",
    "\n",
    "        # save image\n",
    "        if resized_img.mode in (\"RGBA\") and (\".jpg\" or \".jpeg\" in image_path):\n",
    "            resized_img = resized_img.convert(\"RGB\")\n",
    "\n",
    "        resized_img = resized_img.save(image_path)\n",
    "        return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_scale(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    gray_img = ImageOps.grayscale(image)\n",
    "    gray_img = gray_img.save(image_path)\n",
    "    return gray_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in df.values:\n",
    "    resized = resize(os.path.join(processed_data_dir, label, image))\n",
    "    gray_img = gray_scale(os.path.join(processed_data_dir, label, image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: \n",
      "1721       328.jpg\n",
      "2934       308.jpg\n",
      "918         89.jpg\n",
      "1737       340.jpg\n",
      "1610    23_(1).jpg\n",
      "Name: image, dtype: object\n",
      "(2503,)\n",
      "\n",
      "X_test: \n",
      "349     istockphoto-1395855828-612x612.jpg\n",
      "3321                                66.jpg\n",
      "93                                a.91.jpg\n",
      "3130                               z.8.jpg\n",
      "3124                              z.29.jpg\n",
      "Name: image, dtype: object\n",
      "(1073,)\n",
      "\n",
      "y_train: \n",
      "1721        khafre_pyramid\n",
      "2934                sphinx\n",
      "918     colossoi_of_memnon\n",
      "1737        khafre_pyramid\n",
      "1610        khafre_pyramid\n",
      "Name: label, dtype: object\n",
      "(2503,)\n",
      "\n",
      "y_test: \n",
      "349     bent_pyramid_for_senefru\n",
      "3321          temple_of_kom_ombo\n",
      "93                     akhenaten\n",
      "3130        statue_of_king_zoser\n",
      "3124        statue_of_king_zoser\n",
      "Name: label, dtype: object\n",
      "(1073,)\n"
     ]
    }
   ],
   "source": [
    "# split into test and training datasets\n",
    "X = df[\"image\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, train_size= 0.7)\n",
    "\n",
    "print(\"X_train: \")\n",
    "print(X_train.head())\n",
    "print(X_train.shape)\n",
    "print(\"\")\n",
    "print(\"X_test: \")\n",
    "print(X_test.head())\n",
    "print(X_test.shape)\n",
    "print(\"\")\n",
    "\n",
    "print(\"y_train: \")\n",
    "print(y_train.head())\n",
    "print(y_train.shape)\n",
    "print(\"\")\n",
    "print(\"y_test: \")\n",
    "print(y_test.head())\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuing this project\n",
    "\n",
    "In order to continue working on the project, the following questions need to be answered:\n",
    "\n",
    "* How do I tell the algorithm to cluster into 2 groups, sculpture and structure, in an unsupervised approach?\n",
    "    * How can it decipher that an image is a structure or sculpture?\n",
    "* Should the set up of a CNN or pixel boundaries be done in at this step?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
